apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: multi-node-test
spec:
  slotsPerWorker: 8
  runPolicy:
    cleanPodPolicy: Running
    backoffLimit: 1
  mpiReplicaSpecs:
    Launcher:
      restartPolicy: Never
      replicas: 1
      template:
        spec:
          restartPolicy: Never
          serviceAccountName: haoc3
          nodeSelector:
            brightcomputing.com/node-category: 'gaudi'
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: kubernetes.io/hostname
                        operator: In
                        values:
                          - vgr-4-03
                          - vgr-4-06
                          - vgr-2-02
                          - vgr-3-03
                          - vgr-6-02
                          - vgr-2-04
                          - vgr-7-01
                          - vgr-7-02
                          - vgr-7-03
                          - vgr-7-04
                          - vgr-7-05
                          - vgr-7-06
                          - vgr-6-01
                          - vgr-6-02
                          - vgr-6-03
                          - vgr-6-04
                          - vgr-6-05
                          - vgr-6-06
          hostNetwork: false
          volumes:
            - name: home
              hostPath:
                path: /home/haoc3
                type: Directory
            - name: workdir
              hostPath:
                path: /voyager/ceph/users/haoc3
                type: Directory
            - name: scratch
              emptyDir: {}
          containers:
            - name: gaudi-launcher
              # image: vault.habana.ai/gaudi-docker/1.11.0/ubuntu22.04/habanalabs/pytorch-installer-2.0.1:latest
              # image: vault.habana.ai/gaudi-docker/1.14.0/ubuntu22.04/habanalabs/pytorch-installer-2.1.1
              image: vault.habana.ai/gaudi-docker/1.11.0/ubuntu22.04/habanalabs/pytorch-installer-2.0.1:latest
              imagePullPolicy: Always
              volumeMounts:
                - name: workdir
                  mountPath: /voyager  
                - name: scratch
                  mountPath: /scratch
                - name: home
                  mountPath: /home
              env:
                - name: POD_NAME_ID
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: POD_NODE_HOSTNAME
                  valueFrom:
                    fieldRef:
                      fieldPath: spec.nodeName
                - name: CEPH
                  value: '/voyager'
                - name: LOCAL_SCRATCH_DIR
                  value: '/scratch'
                - name: MPI_ROOT
                  value: '/opt/amazon/openmpi'
              command: ["/bin/bash", "-c"] 
              args:
              - >-
                    export HOME=/voyager/ceph/users/haoc3;
                    export PATH=$HOME/.local/bin:$PATH;

                    HOSTSFILE=$OMPI_MCA_orte_default_hostfile;
                    MASTER_ADDR="$(head -n 1 $HOSTSFILE | sed -n s/[[:space:]]slots.*//p)";
                    echo "${MASTER_ADDR}";
                    NUM_NODES=$(wc -l < $HOSTSFILE);
                    CARDS_PER_NODE=8;
                    N_CARDS=$((NUM_NODES*CARDS_PER_NODE));
                    echo "${N_CARDS}";
                    hl-smi;

                    sleep 30;
                    
                    cd /voyager/research/test_hanaba/Model-References_110/PyTorch/computer_vision/classification/torchvision;
                    mpirun -n ${N_CARDS} --allow-run-as-root -bind-to none --map-by ppr:4:socket:PE=6 --rank-by core --report-bindings --tag-output --prefix "${MPI_ROOT}" -x MASTER_ADDR=$MASTER_ADDR python3 -u train.py --data-path=/voyager/datasets/imagenet/ImageNet/ --model=resnet50 --device=hpu --batch-size=256 --epochs=90 --print-freq=25 --workers=12 --output-dir=. --seed=123 --autocast --custom-lr-values 0.275 0.45 0.625 0.8 0.08 0.008 0.0008 --custom-lr-milestones 1 2 3 4 30 60 80 --dl-time-exclude=False --deterministic
    Worker:
        replicas: 3
        template:
          spec:
            restartPolicy: Never
            serviceAccountName: haoc3
            nodeSelector:
              brightcomputing.com/node-category: 'gaudi'
            # hostIPC: true
            volumes:
              - name: home
                hostPath:
                  path: /home/haoc3
                  type: Directory
              - name: workdir
                hostPath:
                  path: /voyager/ceph/users/haoc3
                  type: Directory
              - name: scratch
                emptyDir: {}
            containers:
              - name: gaudi-worker
                # image: vault.habana.ai/gaudi-docker/1.11.0/ubuntu22.04/habanalabs/pytorch-installer-2.0.1:latest
                # image: vault.habana.ai/gaudi-docker/1.14.0/ubuntu22.04/habanalabs/pytorch-installer-2.1.1
                image: vault.habana.ai/gaudi-docker/1.11.0/ubuntu22.04/habanalabs/pytorch-installer-2.0.1:latest
                imagePullPolicy: Always
                resources:
                  requests:
                    cpu: 64
                    memory: 400Gi
                    habana.ai/gaudi: 8
                    hugepages-2Mi: 96000Mi
                  limits:
                    cpu: 64
                    memory: 400Gi
                    habana.ai/gaudi: 8
                    hugepages-2Mi: 96000Mi
                volumeMounts:
                  - name: workdir
                    mountPath: /voyager  
                  - name: scratch
                    mountPath: /scratch
                  - name: home
                    mountPath: /home
                env:
                  - name: POD_NAME_ID
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.name
                  - name: POD_NODE_HOSTNAME
                    valueFrom:
                      fieldRef:
                        fieldPath: spec.nodeName
                  - name: CEPH
                    value: '/voyager'
                  - name: LOCAL_SCRATCH_DIR
                    value: '/scratch'
                  - name: MPI_ROOT
                    value: '/opt/amazon/openmpi'